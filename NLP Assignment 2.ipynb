{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bdb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus is simply Latin for body. So, A body of texts is called Corpus and when you have several such collections of texts, you have a Corpora. A body of linguistic data from a particular language, in the form of recorded utterances (speech) or written (typed) texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf65744",
   "metadata": {},
   "outputs": [],
   "source": [
    "A token is the smallest individual unit in a python program. All statements and instructions in a program are built with tokens. The various tokens in python are : 1. Keywords: Keywords are words that have some special meaning or significance in a programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2792756",
   "metadata": {},
   "outputs": [],
   "source": [
    "From the table above, it’s clear that unigram means taking only one word at a time, bigram means taking two words at a time and trigram means taking three words at a time. We will be implementing only till trigrams here in this blog. Feel free to proceed ahead and explore 4 grams,5-grams, and so on from your take-aways from the blog!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ffb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unigrams or 1-grams  \n",
    "To generate 1-grams we pass the value of n=1 in ngrams function of NLTK. But first, we split the sentence into tokens and then pass these tokens to ngrams function.\n",
    "\n",
    "As we can see we have got one word in each tuple for the Unigram model.\n",
    "\n",
    "In [1]:\n",
    "from nltk.util import ngrams\n",
    "\n",
    "n = 1\n",
    "sentence = 'You will face many defeats in life, but never let yourself be defeated.'\n",
    "unigrams = ngrams(sentence.split(), n)\n",
    "\n",
    "for item in unigrams:\n",
    "    print(item)\n",
    "[Out] :\n",
    "('You',)\n",
    "('will',)\n",
    "('face',)\n",
    "('many',)\n",
    "('defeats',)\n",
    "('in',)\n",
    "('life,',)\n",
    "('but',)\n",
    "('never',)\n",
    "('let',)\n",
    "('yourself',)\n",
    "('be',)\n",
    "('defeated.',)\n",
    "Bigrams or 2-grams\n",
    "For generating 2-grams we pass the value of n=2 in ngrams function of NLTK. But first, we split the sentence into tokens and then pass these tokens to ngrams function.\n",
    "\n",
    "As we can see we have got two adjacent words in each tuple in our Bigrams model.\n",
    "\n",
    "In [2]:\n",
    "from nltk.util import ngrams\n",
    "\n",
    "n = 2\n",
    "sentence = 'The purpose of our life is to happy'\n",
    "unigrams = ngrams(sentence.split(), n)\n",
    "\n",
    "for item in unigrams:\n",
    "    print(item)\n",
    "[Out] :\n",
    "('The', 'purpose')\n",
    "('purpose', 'of')\n",
    "('of', 'our')\n",
    "('our', 'life')\n",
    "('life', 'is')\n",
    "('is', 'to')\n",
    "('to', 'happy')\n",
    "Trigrams or 3-grams \n",
    "In case of 3-grams, we pass the value of n=3 in ngrams function of NLTK. But first, we split the sentence into tokens and then pass these tokens to ngrams function.\n",
    "\n",
    "As we can see we have got three words in each tuple for the Trigram model.\n",
    "\n",
    "In [3]:\n",
    "from nltk.util import ngrams\n",
    "\n",
    "n = 3\n",
    "sentence = 'Whoever is happy will make others happy too'\n",
    "unigrams = ngrams(sentence.split(), n)\n",
    "\n",
    "for item in unigrams:\n",
    "    print(item)\n",
    "[Out] :\n",
    "('Whoever', 'is', 'happy')\n",
    "('is', 'happy', 'will')\n",
    "('happy', 'will', 'make')\n",
    "('will', 'make', 'others')\n",
    "('make', 'others', 'happy')\n",
    "('others', 'happy', 'too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b801e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Load your text in the input form on the left, set the value for n, and you'll instantly get n-grams in the output area. Powerful, free, and fast. Load text – get n-grams. Created by developers from team Browserling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lemmatization technique is like stemming. The output we will get after lemmatization is called ‘lemma’, which is a root word rather than root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing. NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReaderclass to find a lemma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc9f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "In corpus linguistics, part-of-speech tagging ( POS tagging or PoS tagging or POST ), also called grammatical tagging is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3086b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chunking is somewhere between part of speech (POS) tagging and full language parsing, hence the name shallow parsing. If chunkers are an inbetween stage then why are they relevant? The answer comes down to utility and speed. POS tagging is very fast but often doesn’t provide a ton of utility for information extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b86130",
   "metadata": {},
   "outputs": [],
   "source": [
    "One such type of chunking is NP-chunking, or noun phrase chunking. A noun phrase is a phrase that contains a noun and operates, as a unit, as a noun. A popular form of noun phrase begins with a determiner DT, which specifies the noun being referenced, followed by any number of adjectives JJ, which describe the noun, and ends with a noun NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d573a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorize Tickets in Customer Support. If you’re dealing with a rising number of customer support tickets, you can use...\n",
    "Gain Insights from Customer Feedback. Online reviews are a great source of customer feedback: they can provide rich...\n",
    "Content Recommendation. Many modern applications (like Netflix and YouTube) rely on recommendation systems to create...\n",
    "Process Resumes. Recruiters spend many hours of their day going through resumes, looking for the right candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d5276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
