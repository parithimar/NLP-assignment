{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "The vanilla autoencoder, as proposed by Hinton, consists of only one hidden layer. The number of neurons in the hidden layer is less than the number of neurons in the input (or output) layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Image: awesomeopensource.com\n",
    "A sparse autoencoder is simply an autoencoder whose training criterion involves a sparsity penalty. In most cases, we would construct our loss function by penalizing activations of hidden layers so that only a few nodes are encouraged to activate when a single sample is fed into the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d5683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Denoising autoencoders (DAE) try to achieve a good representation by changing the reconstruction criterion. Indeed, DAEs take a partially corrupted input and are trained to recover the original undistorted input. In practice, the objective of denoising autoencoders is that of cleaning the corrupted input, or denoisin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Image: researchgate.net\n",
    "Convolutional Autoencoders Recognizing gestures and actions Autoencoders are a type of neural network in deep learning that comes under the category of unsupervised learning. Autoencoders can be used to learn from the compressed representation of the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb652617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Stacked Autoencoders is a neural network with multiple layers of sparse autoencoders\n",
    "When we add more hidden layers than just one hidden layer to an autoencoder, it helps to reduce a high dimensional data...\n",
    "Each hidden layer is a more compact representation than the last hidden layer\n",
    "We can also denoise the input and then pass the data through the stacked autoencoders called as stacked denoising...\n",
    "In Stacked Denoising Autoencoders, input corruption is used only for initial denoising. This helps learn important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Once fit, the encoder part of the model can be used to encode or compress sequence data that in turn may be used in data visualizations or as a feature vector input to a supervised learning model. In this post, you will discover the LSTM Autoencoder model and how to implement it in Python using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extractive Summarization essentially involves extracting particular pieces of text (usually sentences) based on predefined weights assigned to the important words where the selection of the text depends on the weights of the words in it. Usually, the default weights are assigned according to the frequency of occurrence of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28819749",
   "metadata": {},
   "outputs": [],
   "source": [
    "A Brief Introduction to Abstractive Summarization. Summarization is the ability to explain a larger piece of literature...\n",
    "The Dataset. For this task, I have used the Inshorts dataset. Inshorts is a service that collects news from various...\n",
    "Preprocessing. Here we perform basic preprocessing that is required to train any NLP model. For recognizing the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "A heuristic search algorithm that examines a graph by extending the most promising node in a limited set is known as beam search. Beam search is a heuristic search technique that always expands the W number of the best nodes at each level. It progresses level by level and moves downwards only from the best W nodes at each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7111c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "The process of normalization involves applying rules to a set of data. Each of these rules transforms the data to a certain structure, called a normal form. There are three main normal forms that you should consider (Actually, there are six normal forms in total, but the first three are the most common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Database normalization is the process of structuring a database, usually a relational database, in accordance with a series of so-called normal forms in order to reduce data redundancy and improve data integrity. It was first proposed by Edgar F. Codd as part of his relational model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89776c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUGE that is an abbreviation of Recall Oriented Understudy for Gisting Evaluation is a set of metrics used for the evaluation of automatic text summarization and machine translations. The metrics basically compare automatically generated summary with reference summary or multiple reference summaries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
